{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhpark3\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "#from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats.mstats import zscore # This is to standardized the parameters\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 45)\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# fpath=\"Datasets\\Data_M_2.8_R_0.5_S_4_Sec_256_2D_129_45.pkl\"\n",
    "# pkl_file = open(fpath, 'rb')\n",
    "# data = pickle.load(pkl_file)\n",
    "# label=\"Datasets\\Label_M_2.8_R_0.5_S_4_Sec_256.npy\"\n",
    "# label=np.load(label)\n",
    "# print(data.shape)\n",
    "# print(label.shape)\n",
    "\n",
    "events = np.load(\"Datasets\\DataDetection_M_2.8_R_0.5_S_4_Sec_256.npy\")\n",
    "label = np.load(\"Datasets\\LabelDetection_M_2.8_R_0.5_S_4_Sec_256.npy\")\n",
    "times = np.load(\"Datasets/TimeDetection_M_2.8_R_0.5_S_4_Sec_256.npy\") # features, # samples\n",
    "times = (times - times[0,:]) * 3600 * 24 # set time to 0 and in seconds\n",
    "fs = (times[:,0] < 60).nonzero()[0].shape[0] / 60 # sampling frequency\n",
    "#fs=1\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "_, _, Sxx = spectrogram(events[:,0], fs)\n",
    "spectrogram_shape = Sxx.shape\n",
    "print(spectrogram_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 771)\n",
      "(771, 1)\n"
     ]
    }
   ],
   "source": [
    "print(events.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times.shape\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((events.shape[1], spectrogram_shape[0], spectrogram_shape[1]))\n",
    "for i in range(events.shape[1]):\n",
    "    _, _, Sxx = spectrogram(events[:,i], fs)\n",
    "    data[i, :, :] = np.log10(Sxx)\n",
    "\n",
    "data = data[:,:,:,np.newaxis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616, 129, 45, 1)\n",
      "(616, 2)\n",
      "(771, 129, 45, 1)\n",
      "(771, 1)\n"
     ]
    }
   ],
   "source": [
    "def split_reshape_dataset(X, Y, ratio):\n",
    "    #X = X.T[:,:,np.newaxis, np.newaxis]\n",
    "    #Y = Y.T\n",
    "    m = X.shape[0] # number of samples\n",
    "    sortInd = np.arange(m)\n",
    "    np.random.shuffle(sortInd)\n",
    "    nTrain = int(ratio * m)\n",
    "    X_train = X[sortInd[:nTrain], :, :, :]\n",
    "    Y_train = Y[sortInd[:nTrain],:]\n",
    "    X_test = X[sortInd[nTrain:], :, :, :]\n",
    "    Y_test = Y[sortInd[nTrain:],:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "#data = data[300:700,:]\n",
    "#data = (data - np.mean(data, axis = 0, keepdims= True)) / np.std(data, axis = 0, keepdims = True)\n",
    "#data=zscore(data)\n",
    "\n",
    "RatioTraining=0.8; # 0.8 before\n",
    "X_train, X_test, Y_train, Y_test = split_reshape_dataset(data, label, RatioTraining)\n",
    "Y_train =convert_to_one_hot(Y_train,2).T\n",
    "Y_test = convert_to_one_hot(Y_test,2).T\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "i = 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32,shape=(None, n_H0, n_W0, n_C0))#None\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,n_y))#None\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "    filtersize1=4; # originally 4\n",
    "    filtersize2=2; # originally 2\n",
    "    NumFilters1=8; #4\n",
    "    NumFilters2=16; #8\n",
    "    W1 = tf.get_variable(\"W1\", [16, 4, 1, NumFilters1], initializer = tf.contrib.layers.xavier_initializer(seed = 0))#None\n",
    "    W2 = tf.get_variable(\"W2\", [8, 2, NumFilters1, NumFilters2], initializer = tf.contrib.layers.xavier_initializer(seed = 0))#None\n",
    "    \n",
    "#    W1 = tf.get_variable(\"W1\", [filtersize1, 1, 1, NumFilters1], initializer = tf.contrib.layers.xavier_initializer(seed = 0))#None\n",
    "#    W2 = tf.get_variable(\"W2\", [filtersize2, 1, NumFilters1, NumFilters2], initializer = tf.contrib.layers.xavier_initializer(seed = 0))#None\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')#None\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)#None\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "#    P1 = tf.nn.max_pool(A1, ksize = [1,128,1,1], strides = [1,1,1,1], padding = 'SAME')#None\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,16,4,1], strides = [1,1,1,1], padding = 'SAME')#None\n",
    "#    P1 = tf.nn.max_pool(A1, ksize = [1,4,4,1], strides = [1,1,1,1], padding = 'SAME')#None\n",
    "\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')#None\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "#    P2 = tf.nn.max_pool(A2, ksize = [1,64,1,1], strides = [1,1,1,1], padding = 'SAME')#None\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,8,2,1], strides = [1,1,1,1], padding = 'SAME')#None\n",
    "\n",
    "# FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)#None\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, num_outputs=2,activation_fn=None)\n",
    "    \n",
    "    return Z3, W1, W2\n",
    "\n",
    "def compute_cost(Z3, Y, W1, W2, beta):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    m = int(Y.get_shape()[1])\n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z3, labels = Y) \n",
    "    regularizer = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2)\n",
    "    #egularizer = sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    cost = tf.reduce_mean(cost + 1/m* beta * regularizer)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 10, minibatch_size = 50, print_cost = True, beta = 0.1):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)#None\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3, W1, W2 = forward_propagation(X, parameters)#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y, W1, W2, beta)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            #print(Y_train.shape)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})#None\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "         \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 7.577497\n",
      "Cost after epoch 5: 0.723786\n",
      "Cost after epoch 10: 0.538039\n",
      "Cost after epoch 15: 0.477135\n",
      "Cost after epoch 20: 0.489441\n",
      "Cost after epoch 25: 0.333792\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2190ef4a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99025977\n",
      "Test Accuracy: 0.8516129\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test, num_epochs =30, learning_rate = 0.001, beta = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50843061])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label)/label.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
