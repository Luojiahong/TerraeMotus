{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "#from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 138)\n",
      "(138, 1)\n",
      "(124, 128, 1, 1)\n",
      "(124, 2)\n",
      "(14, 128, 1, 1)\n",
      "(14, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"DataMos.npy\")\n",
    "label = np.load(\"LabelMos.npy\")\n",
    "# time = np.load(\"Time.npy\")\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "def split_reshape_dataset(X, Y, ratio):\n",
    "    X = X.T[:,:,np.newaxis, np.newaxis]\n",
    "    Y = Y.T\n",
    "    m = X.shape[0] # number of samples\n",
    "    sortInd = np.arange(m)\n",
    "    np.random.shuffle(sortInd)\n",
    "    nTrain = int(ratio * m)\n",
    "    X_train = X[sortInd[:nTrain], :, :, :]\n",
    "    Y_train = Y[:, sortInd[:nTrain]]\n",
    "    X_test = X[sortInd[nTrain:], :, :, :]\n",
    "    Y_test = Y[:, sortInd[nTrain:]]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "data = (data - np.mean(data, axis = 0)) / np.std(data, axis = 0)\n",
    "RatioTraining=0.90; # 0.8 before\n",
    "X_train, X_test, Y_train, Y_test = split_reshape_dataset(data, label, RatioTraining)\n",
    "Y_train =convert_to_one_hot(Y_train,2).T\n",
    "Y_test = convert_to_one_hot(Y_test,2).T\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[2., 3.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.matrix('1 2; 3 4')\n",
    "print(test)\n",
    "np.mean(test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=(None, n_H0, n_W0, n_C0))#None\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,n_y))#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "    filtersize1=64; # originally 4\n",
    "    filtersize2=32; # originally 2\n",
    "    NumFilters1=8; #8\n",
    "    NumFilters2=16; #16\n",
    "    \n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [filtersize1, 1, 1, NumFilters1], initializer = tf.contrib.layers.xavier_initializer(seed = 0))#None\n",
    "    W2 = tf.get_variable(\"W2\", [filtersize2, 1, NumFilters1, NumFilters2], initializer = tf.contrib.layers.xavier_initializer(seed = 0))#None\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')#None\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)#None\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,1,1], strides = [1,8,1,1], padding = 'SAME')#None\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')#None\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,1,1], strides = [1,4,1,1], padding = 'SAME')#None\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)#None\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, num_outputs=2,activation_fn=None)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.002,\n",
    "          num_epochs = 100, minibatch_size = 10, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)#None\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)#None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            #print(Y_train.shape)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})#None\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.729745\n",
      "Cost after epoch 5: 0.120663\n",
      "Cost after epoch 10: 0.009132\n",
      "Cost after epoch 15: 0.001923\n",
      "Cost after epoch 20: 0.001126\n",
      "Cost after epoch 25: 0.000812\n",
      "Cost after epoch 30: 0.000552\n",
      "Cost after epoch 35: 0.000432\n",
      "Cost after epoch 40: 0.000376\n",
      "Cost after epoch 45: 0.000292\n",
      "Cost after epoch 50: 0.000231\n",
      "Cost after epoch 55: 0.000201\n",
      "Cost after epoch 60: 0.000169\n",
      "Cost after epoch 65: 0.000151\n",
      "Cost after epoch 70: 0.000127\n",
      "Cost after epoch 75: 0.000113\n",
      "Cost after epoch 80: 0.000097\n",
      "Cost after epoch 85: 0.000094\n",
      "Cost after epoch 90: 0.000075\n",
      "Cost after epoch 95: 0.000071\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13970f13780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.85714287\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
